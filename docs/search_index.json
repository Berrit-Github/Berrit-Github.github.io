[["index.html", "untitled Chapter 1 Welcome 1.1 Preview book", " untitled John Doe 2023-06-05 Chapter 1 Welcome welcome to my bookdown website. This website contains my portfolio excercises and my cv. you can look throuh the pages with the search bar on the right bookdown::render_book() 1.1 Preview book bookdown::serve_book() "],["ic50-c.elegans-experiment-workflow.html", "Chapter 2 IC50 C.elegans experiment workflow", " Chapter 2 IC50 C.elegans experiment workflow C.elegans plate experiment Data for this experiment was provided by J.Louter (INT/ILC). In the experiment adult C.elegans nematodes were incubated by different concentration of different chemicals. after the incubation the amount of offspring was counted. Ethanol was used as a positive control and S-medium as the negative control. For a full IC50 analysis the averages of the compounds should be merged. this can be plotted out in a line graph. then at the middle between the lowest and highest point on that spot on the X-axis is the IC50. after doing this for all the chemicals they can be compared. first we open and save the data file to our R console. library(readxl) library(tidyverse) onderzoek_data_portfolie_1 &lt;- read_xlsx(&quot;data/CE.LIQ.FLOW.062_Tidydata.xlsx&quot;) now that we imported the data we can check if the data types are rightfully interpreted. by using the head command we can see the first 10 rows and the column names and their assigned types. head(onderzoek_data_portfolie_1) ## # A tibble: 6 × 34 ## plateRow plateColumn vialNr dropCode expType expReplicate expName ## &lt;lgl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 NA NA 1 a experiment 3 CE.LIQ.FLOW.062 ## 2 NA NA 1 b experiment 3 CE.LIQ.FLOW.062 ## 3 NA NA 1 c experiment 3 CE.LIQ.FLOW.062 ## 4 NA NA 1 d experiment 3 CE.LIQ.FLOW.062 ## 5 NA NA 1 e experiment 3 CE.LIQ.FLOW.062 ## 6 NA NA 2 a experiment 3 CE.LIQ.FLOW.062 ## # ℹ 27 more variables: expDate &lt;dttm&gt;, expResearcher &lt;chr&gt;, expTime &lt;dbl&gt;, ## # expUnit &lt;chr&gt;, expVolumeCounted &lt;dbl&gt;, RawData &lt;dbl&gt;, compCASRN &lt;chr&gt;, ## # compName &lt;chr&gt;, compConcentration &lt;chr&gt;, compUnit &lt;chr&gt;, ## # compDelivery &lt;chr&gt;, compVehicle &lt;chr&gt;, elegansStrain &lt;chr&gt;, ## # elegansInput &lt;dbl&gt;, bacterialStrain &lt;chr&gt;, bacterialTreatment &lt;chr&gt;, ## # bacterialOD600 &lt;dbl&gt;, bacterialConcX &lt;dbl&gt;, bacterialVolume &lt;dbl&gt;, ## # bacterialVolUnit &lt;chr&gt;, incubationVial &lt;chr&gt;, incubationVolume &lt;dbl&gt;, … in the data above we can see that Rawdata is dbl but this should be integer. compname is character but should be a factor and compconcentration is character but should be dbl before we can work with the data we are going to change these to the right data type. #install.packages(&quot;ggplot2&quot;) onderzoek_data_portfolie_1$compName &lt;- as.factor(onderzoek_data_portfolie_1$compName) onderzoek_data_portfolie_1$RawData &lt;- as.numeric(onderzoek_data_portfolie_1$RawData) onderzoek_data_portfolie_1$compConcentration &lt;- as.numeric(onderzoek_data_portfolie_1$compConcentration) head(onderzoek_data_portfolie_1) ## # A tibble: 6 × 34 ## plateRow plateColumn vialNr dropCode expType expReplicate expName ## &lt;lgl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 NA NA 1 a experiment 3 CE.LIQ.FLOW.062 ## 2 NA NA 1 b experiment 3 CE.LIQ.FLOW.062 ## 3 NA NA 1 c experiment 3 CE.LIQ.FLOW.062 ## 4 NA NA 1 d experiment 3 CE.LIQ.FLOW.062 ## 5 NA NA 1 e experiment 3 CE.LIQ.FLOW.062 ## 6 NA NA 2 a experiment 3 CE.LIQ.FLOW.062 ## # ℹ 27 more variables: expDate &lt;dttm&gt;, expResearcher &lt;chr&gt;, expTime &lt;dbl&gt;, ## # expUnit &lt;chr&gt;, expVolumeCounted &lt;dbl&gt;, RawData &lt;dbl&gt;, compCASRN &lt;chr&gt;, ## # compName &lt;fct&gt;, compConcentration &lt;dbl&gt;, compUnit &lt;chr&gt;, ## # compDelivery &lt;chr&gt;, compVehicle &lt;chr&gt;, elegansStrain &lt;chr&gt;, ## # elegansInput &lt;dbl&gt;, bacterialStrain &lt;chr&gt;, bacterialTreatment &lt;chr&gt;, ## # bacterialOD600 &lt;dbl&gt;, bacterialConcX &lt;dbl&gt;, bacterialVolume &lt;dbl&gt;, ## # bacterialVolUnit &lt;chr&gt;, incubationVial &lt;chr&gt;, incubationVolume &lt;dbl&gt;, … By using the head command again we can see we have changed the data types. Next we are going to plot the data. we want the component concentration on the X-axis and the number of offspring on the Y-axis. for better viability we give the different components colours and the experimental conditions a different shape library(ggplot2) ggplot(onderzoek_data_portfolie_1, aes(x = compConcentration , y = RawData, colour = compName , shape = expType )) + geom_point() + labs(x = &quot;component concentration (nM)&quot; , y = &quot;number of offspring&quot; ) hmmm.. that does not tell us a whole lot about the data now does it. lets add a log10 transformation to the X-axis to even it out more. next we are going to add some jitter to points just to see the individual points better. library(ggplot2) ggplot(onderzoek_data_portfolie_1, aes(x = log10(compConcentration) , y = RawData, colour = compName , shape = expType )) + geom_jitter(width = 0.1) + labs(x = &quot;component concentration on log10 scale (nM)&quot; , y = &quot;number of offspring&quot; ) + xlim(-4.5 , 2) To really understand the effects of each component we are going to normalize the data. first we make the mean value of the negative control equal to one. then we will convert the other data to be a fraction of the negative control. we make a new vector with the new data and plot this like we did before. #view(onderzoek_data_portfolie_1) ngative_stuff &lt;- dplyr::filter(onderzoek_data_portfolie_1 ,expType == &quot;controlNegative&quot; ) mean(ngative_stuff$RawData) ## [1] 85.9 onderzoek_data_portfolie_1_newraw &lt;- onderzoek_data_portfolie_1 onderzoek_data_portfolie_1_newraw$RawData &lt;- onderzoek_data_portfolie_1_newraw$RawData/mean(ngative_stuff$RawData) ggplot(onderzoek_data_portfolie_1_newraw, aes(x = log10(compConcentration) , y = RawData, colour = compName , shape = expType )) + geom_jitter(width = 0.1) + labs(x = &quot;component concentration on log10 scale (nM)&quot; , y = &quot;number of offspring&quot; ) + xlim(-4.5 , 2) "],["map-tree.html", "Chapter 3 map tree", " Chapter 3 map tree fs::dir_tree(&quot;data/daur2_tidy_data&quot;) ## data/daur2_tidy_data ## ├── metagenomics_species_identification ## └── RNA_sequencing "],["the-importance-of-reproducible-data..html", "Chapter 4 The importance of reproducible data.", " Chapter 4 The importance of reproducible data. In this mark down i will show you the importance of clear and readable data. For this I have selected an open source research with experimental data. I have used this article: “Generalized additive models to analyze non-linear trends in biomedical longitudinal data using R: Beyond repeated measures ANOVA and Linear Mixed Models” https://doi.org/10.1101/2021.06.10.447970. his article explorers the uses of repeated measures analysis of variance (rm-ANOVA), linear mixed models (LMEMs) and Generalized additive models (GAMs). it shows that rm-ANOVA and LMEMs are used to look for linear trends is gathered data, But in most biomedical research there are no linear trends and the use of these Techniques can lead to biased conclusions. In contrast, GAMs do not assume linear trends in data and is there for more trust worthy the visualize this with simulated data about the oxygen saturation in tumors. I have ranked this article according to the following Transparency Criteria. Transparency Criteria Definition Response Type Study Purpose A concise statement in the introduction of the article, often in the last paragraph, that establishes the reason the research was conducted. Also called the study objective. TRUE Data Availability Statement A statement, in an individual section offset from the main body of text, that explains how or if one can access a study’s data. The title of the section may vary, but it must explicitly mention data; it is therefore distinct from a supplementary materials section. TRUE (it is not a section but it is mentiond where to find the data.) Data Location Where the article’s data can be accessed, either raw or processed. https://github.com/aimundo/GAMs-biomedical-research a github repository. Study Location Author has stated in the methods section where the study took place or the data’s country/region of origin. FALSE: Author Review The professionalism of the contact information that the author has provided in the manuscript. TRUE Ariel I. Mundo1, Timothy J. Muldoon1* and John R. Tipton2 Corresponding author; email: tmuldoon@uark.edu Ethics Statement A statement within the manuscript indicating any ethical concerns, including the presence of sensitive data. FALSE Funding Statement A statement within the manuscript indicating whether or not the authors received funding for their research. TRUE Code Availability Authors have shared access to the most updated code that they used in their study, including code used for analysis. TRUE The article ranks good on most of the points the criteria, 4.0.1 the second part of data For the second part of looking at reproducing papers we are going to look at actual R code. the paper used is the same as in the previous page.first we take a look at the data https://doi.org/10.1101/2021.06.10.447970 The code used in the paper is spread over multiple R scripts this makes them easier to distinguish them from each other. The codes are not super complicated and where needed they give a comment about what the code is needed for. I would give this code a 4.4 its overall very good I would separate a few of the functions into separated R chunks but that is more of a personal preference Next we are going to run the code and try to recreate the following picture (FILL IN EXAMPLE PICTURE) Voorbeeld figuur remaking this was not super difficult in the main_manuscript file they gave all the packages needed to run the code as well as the seed they used. #the packages needed to run the code library(patchwork) library(tidyverse) library(mvnfast) ## ## Attaching package: &#39;mvnfast&#39; ## The following object is masked from &#39;package:lubridate&#39;: ## ## ms library(nlme) ## ## Attaching package: &#39;nlme&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## collapse library(mgcv) ## This is mgcv 1.8-42. For overview type &#39;help(&quot;mgcv-package&quot;)&#39;. ## ## Attaching package: &#39;mgcv&#39; ## The following objects are masked from &#39;package:mvnfast&#39;: ## ## dmvn, rmvn library(gratia) library(scico) set.seed(2021) #set seed for reproducibility thm1&lt;-scale_fill_scico_d(palette=&quot;tokyo&quot;,begin=0.3, end=0.8, direction = -1, aesthetics = c(&quot;colour&quot;,&quot;fill&quot;)) ## This function plots the rm-ANOVA and LMEM for the data simulated in example.R plot_example &lt;- function(sim_dat, option=&quot;simple&quot;) { txt&lt;-20 #plot simulated data (scatterplot) p1 &lt;- sim_dat$dat %&gt;% ggplot(aes(x = time, y = y, group = treatment, color = treatment) ) + geom_point(show.legend=FALSE, alpha = 0.5) + labs(y=&#39;response&#39;)+ geom_line(aes(x = time, y = mu, color = treatment), show.legend=FALSE) + theme_classic() + theme(plot.title = element_text(size = txt, face = &quot;bold&quot;), text=element_text(size=txt))+ thm1 #plot the simulated data with trajectories per each subject p2 &lt;- sim_dat$dat %&gt;% ggplot(aes(x = time, y = y, group = subject, color = treatment) ) + geom_line(aes(size = &quot;Subjects&quot;), show.legend = FALSE) + # facet_wrap(~ treatment) + geom_line(aes(x = time, y = mu, color = treatment, size = &quot;Simulated Truth&quot;), lty = 1,show.legend = FALSE) + labs(y=&#39;response&#39;)+ scale_size_manual(name = &quot;Type&quot;, values=c(&quot;Subjects&quot; = 0.5, &quot;Simulated Truth&quot; = 3)) + theme_classic()+ theme(plot.title = element_text(size = txt, face = &quot;bold&quot;), text=element_text(size=txt))+ thm1 #plot the errors p3 &lt;- sim_dat$dat %&gt;% ggplot(aes(x = time, y = errors, group = subject, color = treatment)) + geom_line(show.legend=FALSE) + labs(y=&#39;errors&#39;)+ theme_classic()+ theme(plot.title = element_text(size = txt, face = &quot;bold&quot;), text=element_text(size=txt))+ thm1 #plot the model predictions for rm-ANOVA p4 &lt;- ggplot(sim_dat$dat, aes(x = time, y = y, color = treatment)) + geom_point(show.legend = FALSE, alpha=0.5)+ labs(y=&#39;response&#39;)+ geom_line(aes(y = predict(sim_dat$fit_anova), group = subject, size = &quot;Subjects&quot;),show.legend = FALSE) + geom_line(data = sim_dat$pred_dat, aes(y = predict(sim_dat$fit_anova, level = 0, newdata = sim_dat$pred_dat), size = &quot;Population&quot;), show.legend=FALSE) + guides(color = guide_legend(override.aes = list(size = 2)))+ scale_size_manual(name = &quot;Predictions&quot;, values=c(&quot;Subjects&quot; = 0.5, &quot;Population&quot; = 3)) + theme_classic() + theme(plot.title = element_text(size = txt, face = &quot;bold&quot;), text=element_text(size=txt))+ thm1 #plot the LMEM predictions p5 &lt;- ggplot(sim_dat$dat, aes(x = time, y = y, color = treatment)) + geom_point(alpha = 0.5)+ labs(y=&#39;response&#39;)+ geom_line(aes(y = predict(sim_dat$fit_lme), group = subject, size = &quot;Subjects&quot;)) + geom_line(data = sim_dat$pred_dat, aes(y = predict(sim_dat$fit_lme, level = 0, newdata = sim_dat$pred_dat), size = &quot;Population&quot;)) + guides(color = guide_legend(override.aes = list(size = 2)))+ scale_size_manual(name = &quot;Predictions&quot;, values=c(&quot;Subjects&quot; = 0.5, &quot;Population&quot; = 3)) + theme_classic() + theme(plot.title = element_text(size = txt, face = &quot;bold&quot;), text=element_text(size=txt))+ thm1 if(option==&#39;simple&#39;){ return((p1+p4+p5)+plot_layout(nrow=1)+plot_annotation(tag_levels = &#39;A&#39;)) } else { return((p1+p3+p2+p4+p5)+plot_layout(nrow=1)+plot_annotation(tag_levels = &#39;A&#39;)) } } ## Example with linear response. This function generates either linear or quadratic mean #responses with correlated or uncorrelated errors and fits a linear model to the data. example &lt;- function(n_time = 6, #number of time points fun_type = &quot;linear&quot;, #type of response error_type = &quot;correlated&quot;) { if (!(fun_type %in% c(&quot;linear&quot;, &quot;quadratic&quot;))) stop(&#39;fun_type must be either &quot;linear&quot;, or &quot;quadratic&quot;&#39;) if (!(error_type %in% c(&quot;correlated&quot;, &quot;independent&quot;))) stop(&#39;fun_type must be either &quot;correlated&quot;, or &quot;independent&quot;&#39;) x &lt;- seq(1,6, length.out = n_time) #Create mean response matrix: linear or quadratic mu &lt;- matrix(0, length(x), 2) # linear response if (fun_type == &quot;linear&quot;) { mu[, 1] &lt;- - (0.25*x)+2 mu[, 2] &lt;- 0.25*x+2 } else { # quadratic response (non-linear) mu[, 1] &lt;- -(0.25 * x^2) +1.5*x-1.25 mu[, 2] &lt;- (0.25 * x^2) -1.5*x+1.25 } #create an array where individual observations per each time point for each group are to be stored. Currently using 10 observations per timepoint y &lt;- array(0, dim = c(length(x), 2, 10)) #Create array to store the &quot;errors&quot; for each group at each timepoint. The &quot;errors&quot; are the #between-group variability in the response. errors &lt;- array(0, dim = c(length(x), 2, 10)) #create an array where 10 observations per each time point for each group are to be stored #The following cycles create independent or correlated responses. To each value of mu (mean response per group) a randomly generated error (correlated or uncorrelated) is added and thus the individual response is created. if (error_type == &quot;independent&quot;) { ## independent errors for (i in 1:2) { for (j in 1:10) { errors[, i, j] &lt;- rnorm(6, 0, 0.25) y[, i, j] &lt;- mu[, i] + errors[, i, j] } } } else { for (i in 1:2) { # number of treatments for (j in 1:10) { # number of subjects # compound symmetry errors: variance covariance matrix errors[, i, j] &lt;- rmvn(1, rep(0, length(x)), 0.1 * diag(6) + 0.25 * matrix(1, 6, 6)) y[, i, j] &lt;- mu[, i] + errors[, i, j] } } } ## subject random effects ## visualizing the difference between independent errors and compound symmetry ## why do we need to account for this -- overly confident inference #labelling y and errors dimnames(y) &lt;- list(time = x, treatment = 1:2, subject = 1:10) dimnames(errors) &lt;- list(time = x, treatment = 1:2, subject = 1:10) #labeling the mean response dimnames(mu) &lt;- list(time = x, treatment = 1:2) #convert y, mu and errors to dataframes with time, treatment and subject columns dat &lt;- as.data.frame.table(y, responseName = &quot;y&quot;) dat_errors &lt;- as.data.frame.table(errors, responseName = &quot;errors&quot;) dat_mu &lt;- as.data.frame.table(mu, responseName = &quot;mu&quot;) #join the dataframes to show mean response and errors per subject dat &lt;- left_join(dat, dat_errors, by = c(&quot;time&quot;, &quot;treatment&quot;, &quot;subject&quot;)) dat &lt;- left_join(dat, dat_mu, by = c(&quot;time&quot;, &quot;treatment&quot;)) #add time dat$time &lt;- as.numeric(as.character(dat$time)) #label subjects per group dat &lt;- dat %&gt;% mutate(subject = factor(paste(subject, treatment, sep = &quot;-&quot;))) ## repeated measures ANOVA in R #time and treatment interaction model fit_anova &lt;- lm(y ~ time + treatment + time * treatment, data = dat) #LMEM with compound symmetry fit_lme &lt;- lme(y ~ treatment + time + treatment:time, data = dat, random = ~ 1 | subject, correlation = corCompSymm(form = ~ 1 | subject) ) #create a prediction frame where the model can be used for plotting purposes pred_dat &lt;- expand.grid( treatment = factor(1:2), time = unique(dat$time) ) #add model predictions to the dataframe that has the simulated data dat$pred_anova &lt;- predict(fit_anova) dat$pred_lmem &lt;- predict(fit_lme) #return everything in a list return(list( dat = dat, pred_dat = pred_dat, fit_lme = fit_lme, fit_anova=fit_anova )) } Figure 4.1: Simulated responses from two groups with correlated errors using a LMEM and a rm-ANOVA model. Top row: linear response, bottom row: quadratic response. A: Simulated linear data with known mean response (thick lines) and individual responses (points) showing the dispersion of the data. D: Simulated quadratic data with known mean response (thick lines) and individual responses (points) showing the dispersion of the data. B,E: Estimates from the rm-ANOVA model for the mean group response (linear of quadratic). Points represent the original raw data. The rm-ANOVA model not only fails to pick the trend of the quadratic data (E) but also assigns a global estimate that does not take into account the between-subject variation. C, F: Estimates from the LMEM in the linear and quadratic case (subject: thin lines, population: thick lines) . The LMEM incorporates a random effect for each subject, but this model and the rm-ANOVA model are unable to follow the trend of the data and grossly bias the initial estimates for each group in the quadratic case (bottom row). This data was easy to run the addition of the used packages made running this code very easy. therefor I give it a 4.8 out of 5. "],["introduction-projecticum.html", "Chapter 5 introduction projecticum", " Chapter 5 introduction projecticum when an organism ages multiple bodily factors will decrease in function. eyesight , hearing and muscle strength are all examples of this. In case of muscle strength in which muscles mass and function decreases is called sacropenia. Normal and mostly young muscle react on the environmental stimuli to grow such as insulin and leucine. when stimulated they make muscle protein this processes is called muscle protein synthesis (MPS). This process needs to be up kept to counter natural muscle decay. In aged individuals it is shown that due a resistance to stimuli such as insulin and leucine and elderly individuals perform little muscle training, that the balance between MPS and natural muscle decay is in favor the decay of muscles and so causes sacropenia (Miriam van Dijk et al. (2016)). Further research (F. J. Dijk et al. (2018)) shows that leucine is a important factor in the pathway of MPS. The first evidence of this was by feeding young rats a single meal with a high leucine concentration after inspecting the muscles of these rats they showed a higher amount of MPS. additional it also proved that rats who were fed a higher dose of leucine showed more MPS than those with a low dose of leucine revealing a connection between the concentration and the reaction. therefore it showed promise to possibly combat sacropenia in older rats. furthermore luecine controls MPS by being able to stimulate the Mthor pathway the mthor pathway can later stimulate the other other factors such as p70s6k and 4E-BP1 these factors influence the mRNA translation which results in more MPS in muscle cells. These factors were the start of many experiments looking at the different effects of leucine, such as what other factors are involved, different administration methods, and the effects of one or more doses spread over a longer period of time. In the following research it turned out it was not as easy as firstly thought. It shows that older individuals have become more resistent to leucine with age (Miriam van Dijk et al. (2017)) &amp; (Boirie and Guillet (2018)) In order for leucine to work the fed the older rats a higher dose than one would a normal rat and it was seen after eating this meal the rats did have a higher MPS then before eating the meal (Rieu et al. (2003)). One of the most used proteins in this type of research is the whey protein. this protein is quick to digest and is rich with the leucine amino-acid. this protein has a very positive effect on the MPS. Currently a research team by nutricia is looking into how leucine contributes to MPS and if there are plant based alternatives which can have similar effects as the whey protein. after giving the mice one of the experimental plant based protein their aminoacid values are measured. All of these value are compared. The results of this experiment gives a mountain of data to be decoded. to visualize all of this data so it would be easier to compare nutricia called in the help of the HU (hogeschool Utrecht) and their data science students. CV "],["cv.html", "Chapter 6 CV", " Chapter 6 CV "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
