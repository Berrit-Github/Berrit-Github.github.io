---
title: "reproducing papers"
output: html_document
date: "2023-05-22"
---
## the second part of data
```{r , include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
For the second part of looking at reproducing papers we are going to look at actual R code. the paper used is the same as in the previous page.first we take a look at the data https://doi.org/10.1101/2021.06.10.447970


The code used in the paper is spread over multiple R scripts this makes them easier to distinguish them from each other. The codes are not super complicated and where needed they give a comment about what the code is needed for.

I would give this code a 4.4 its overall very good I would separate a few of the functions into separated R chunks but that is more of a personal preference

Next we are going to run the code and try to recreate the following picture


![Voorbeeld figuur](data/osfstorage-archive/Voorbeeld_afbeelding.PNG)

remaking this was not super difficult in the main_manuscript file they gave all the packages needed to run the code as well as the seed they used.

```{r}
#the packages needed to run the code

library(patchwork)
library(tidyverse)
library(mvnfast)
library(nlme)
library(mgcv)
library(gratia)
library(scico)
set.seed(2021) #set seed for reproducibility
thm1<-scale_fill_scico_d(palette="tokyo",begin=0.3, end=0.8, direction = -1, aesthetics = c("colour","fill"))
```

```{r}
## This function plots the rm-ANOVA and LMEM for the data simulated in example.R
plot_example <- function(sim_dat,
                         option="simple") {
    txt<-20

    #plot simulated data (scatterplot)
    p1 <- sim_dat$dat %>%
        ggplot(aes(x = time,
                   y = y,
                   group = treatment,
                   color = treatment)
        ) +
        geom_point(show.legend=FALSE,
                   alpha = 0.5) +
        labs(y='response')+
        geom_line(aes(x = time,
                      y = mu,
                      color = treatment),
                  show.legend=FALSE) +
        theme_classic() +
        theme(plot.title = element_text(size = txt,
                                        face = "bold"),
              text=element_text(size=txt))+
        thm1

    #plot the simulated data with trajectories per each subject
    p2 <- sim_dat$dat %>%
        ggplot(aes(x = time,
                   y = y,
                   group = subject,
                   color = treatment)
        ) +
        geom_line(aes(size = "Subjects"),
                  show.legend = FALSE) +
        # facet_wrap(~ treatment) +
        geom_line(aes(x = time,
                      y = mu,
                      color = treatment,
                      size = "Simulated Truth"),
                  lty = 1,show.legend = FALSE) +
        labs(y='response')+
        scale_size_manual(name = "Type", values=c("Subjects" = 0.5, "Simulated Truth" = 3)) +
        theme_classic()+
        theme(plot.title = element_text(size = txt,
                                        face = "bold"),
              text=element_text(size=txt))+
        thm1

    #plot the errors
    p3 <- sim_dat$dat %>%
        ggplot(aes(x = time,
                   y = errors,
                   group = subject,
                   color = treatment)) +
        geom_line(show.legend=FALSE) +
        labs(y='errors')+
        theme_classic()+
        theme(plot.title = element_text(size = txt,
                                        face = "bold"),
              text=element_text(size=txt))+
        thm1

    #plot the model predictions for rm-ANOVA
    p4 <- ggplot(sim_dat$dat,
                 aes(x = time,
                     y = y,
                     color = treatment)) +
        geom_point(show.legend = FALSE,
                   alpha=0.5)+
        labs(y='response')+
        geom_line(aes(y = predict(sim_dat$fit_anova),
                      group = subject, size = "Subjects"),show.legend = FALSE) +
        geom_line(data = sim_dat$pred_dat,
                  aes(y = predict(sim_dat$fit_anova,
                                  level = 0,
                                  newdata = sim_dat$pred_dat),
                      size = "Population"),
                  show.legend=FALSE) +
        guides(color = guide_legend(override.aes = list(size = 2)))+
        scale_size_manual(name = "Predictions",
                          values=c("Subjects" = 0.5, "Population" = 3)) +
        theme_classic() +
        theme(plot.title = element_text(size = txt,
                                        face = "bold"),
              text=element_text(size=txt))+
        thm1



    #plot the LMEM predictions
    p5 <- ggplot(sim_dat$dat,
                 aes(x = time,
                     y = y,
                     color = treatment)) +
        geom_point(alpha = 0.5)+
        labs(y='response')+
        geom_line(aes(y = predict(sim_dat$fit_lme),
                      group = subject, size = "Subjects")) +
        geom_line(data = sim_dat$pred_dat,
                  aes(y = predict(sim_dat$fit_lme,
                                  level = 0,
                                  newdata = sim_dat$pred_dat),
                      size = "Population")) +
        guides(color = guide_legend(override.aes = list(size = 2)))+
        scale_size_manual(name = "Predictions",
                          values=c("Subjects" = 0.5, "Population" = 3)) +
        theme_classic() +
        theme(plot.title = element_text(size = txt,
                                        face = "bold"),
              text=element_text(size=txt))+
        thm1

    if(option=='simple'){
        return((p1+p4+p5)+plot_layout(nrow=1)+plot_annotation(tag_levels = 'A'))
    }
    else {
    return((p1+p3+p2+p4+p5)+plot_layout(nrow=1)+plot_annotation(tag_levels = 'A'))
    }

}
```


```{r}
## Example with linear response. This function generates either linear or quadratic mean
#responses with correlated or uncorrelated errors and fits a linear model to the data.

example <- function(n_time = 6, #number of time points
                    fun_type = "linear", #type of response
                    error_type = "correlated") {

    if (!(fun_type %in% c("linear", "quadratic")))
        stop('fun_type must be either "linear", or "quadratic"')
    if (!(error_type %in% c("correlated", "independent")))
        stop('fun_type must be either "correlated", or "independent"')


    x <- seq(1,6, length.out = n_time)

    #Create mean response matrix: linear or quadratic
    mu <- matrix(0, length(x), 2)
    # linear response
    if (fun_type == "linear") {
        mu[, 1] <- - (0.25*x)+2
        mu[, 2] <- 0.25*x+2
    } else {
        # quadratic response (non-linear)

        mu[, 1] <-  -(0.25 * x^2) +1.5*x-1.25
        mu[, 2] <- (0.25 * x^2) -1.5*x+1.25
    }

    #create an array where individual observations per each time point for each group are to be stored. Currently using 10 observations per timepoint
    y <- array(0, dim = c(length(x), 2, 10))

    #Create array to store the "errors" for each group at each timepoint. The "errors" are the
    #between-group variability in the response.
    errors <- array(0, dim = c(length(x), 2, 10))
    #create an array where 10 observations per each time point for each group are to be stored

    #The following cycles create independent or correlated responses. To each value of mu (mean response per group) a randomly generated error (correlated or uncorrelated) is added and thus the individual response is created.
    if (error_type == "independent") {
        ## independent errors
        for (i in 1:2) {
            for (j in 1:10) {
                errors[, i, j] <- rnorm(6, 0, 0.25)
                y[, i, j] <- mu[, i] + errors[, i, j]
            }
        }
    } else {
        for (i in 1:2) {     # number of treatments
            for (j in 1:10) {  # number of subjects
                # compound symmetry errors: variance covariance matrix
                errors[, i, j] <- rmvn(1, rep(0, length(x)), 0.1 * diag(6) + 0.25 * matrix(1, 6, 6))
                y[, i, j] <- mu[, i] + errors[, i, j]
            }
        }
    }


    ## subject random effects

    ## visualizing the difference between independent errors and compound symmetry
    ## why do we need to account for this -- overly confident inference

    #labelling y and errors
    dimnames(y) <- list(time = x,
                        treatment = 1:2,
                        subject = 1:10)

    dimnames(errors) <- list(time = x,
                             treatment = 1:2,
                             subject = 1:10)

    #labeling the mean response
    dimnames(mu) <- list(time = x,
                         treatment = 1:2)

    #convert y, mu and errors to  dataframes with time, treatment and subject columns
    dat <- as.data.frame.table(y,
                               responseName = "y")
    dat_errors <- as.data.frame.table(errors,
                                      responseName = "errors")
    dat_mu <- as.data.frame.table(mu,
                                  responseName = "mu")

    #join the dataframes to show mean response and errors per subject
    dat <- left_join(dat, dat_errors,
                     by = c("time", "treatment", "subject"))
    dat <- left_join(dat, dat_mu,
                     by = c("time", "treatment"))
    #add time
    dat$time <- as.numeric(as.character(dat$time))
    #label subjects per group
    dat <- dat %>%
        mutate(subject = factor(paste(subject,
                                      treatment,
                                      sep = "-")))


    ## repeated measures ANOVA in R
    #time and treatment interaction model
    fit_anova <- lm(y ~ time + treatment + time * treatment, data = dat)


    #LMEM with compound symmetry

    fit_lme <- lme(y ~ treatment + time + treatment:time,
                   data = dat,
                   random = ~ 1 | subject,
                   correlation = corCompSymm(form = ~ 1 | subject)
    )


    #create a prediction frame where the model can be used for plotting purposes
    pred_dat <- expand.grid(
        treatment = factor(1:2),
        time = unique(dat$time)
    )

    #add model predictions to the dataframe that has the simulated data
    dat$pred_anova <- predict(fit_anova)
    dat$pred_lmem <- predict(fit_lme)


    #return everything in a list
    return(list(
        dat = dat,
        pred_dat = pred_dat,
        fit_lme = fit_lme,
        fit_anova=fit_anova

    ))
}
```



```{r,include=FALSE,message=FALSE,echo=FALSE}

#calls the scripts example.R and plot_example.R
#source(here::here("scripts","example.R"))
#source(here::here("scripts","plot_example.R"))

A<-plot_example(example(fun_type = "linear", error_type = "correlated"),option='simple')

C<-plot_example(example(fun_type = "quadratic", error_type = "correlated"), option='simple')

```

(ref:l-q-response-caption) Simulated responses from two groups with correlated errors using a LMEM and a rm-ANOVA model. Top row: linear response, bottom row: quadratic response. **A**: Simulated linear data with known mean response (thick lines) and individual responses (points) showing the dispersion of the data. **D**: Simulated quadratic data with known mean response (thick lines) and individual responses (points) showing the dispersion of the data. **B,E**: Estimates from the rm-ANOVA model for the mean group response (linear of quadratic). Points represent the original raw data. The rm-ANOVA model not only fails to pick the trend of the quadratic data (E) but also assigns a global estimate that does not take into account the between-subject variation. **C, F**: Estimates from the LMEM in the linear and quadratic case (subject: thin lines, population: thick lines) . The LMEM incorporates a random effect for each subject, but this model and the rm-ANOVA model are unable to follow the trend of the data and grossly bias the initial estimates for each group in the quadratic case (bottom row).

```{r, l-q-response, fig.width=12, fig.height=7, out.width='100%',fig.align='center', echo=FALSE,message=FALSE,fig.show='hold',fig.cap ='(ref:l-q-response-caption)'}
A/C+plot_annotation(tag_levels = 'A')
```


This data was easy to run the addition of the used packages made running this code very easy. therefor I give it a 4.8 out of 5.




